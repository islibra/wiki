神经网络被支持向量机取代
随机模拟


# 人工智能四要素

+ 算法
+ 算力
+ 数据：特征工程：数据表示（特征抽取：数据转换，如主成分分析，特征选择：不破坏数据取子集），数据整理（数据清洗，缺失数据分析，诱导特征，数据压缩，数据合并），关系发现，异常点检测（Additive Outlier, Innovative Outlier, Temporary Change, Level Shift）
+ 场景


## 机器学习

计算基础：最优化，矩阵计算，概率统计


### 轻量机器学习

1. 计算复杂度低，训练周期短
2. 在线学习，不存储大量训练样本，来一个学一个，模型时时更新
3. 具备先验知识，数据量少依然可以进行模型更新和推断
4. 近似计算求满意解，非最优解，降低计算复杂度


### 非轻量机器学习


#### 无监督学习（数据驱动，聚类）

直接对无标签样本进行聚类。

##### 聚类

- k-均值聚类
  1. 随机挑选聚类中心的位置
  1. 根据样本到中心的距离为样本打标签
  1. 调整聚类中心的位置，如果有变化，继续
  1. 调整样本标签和聚类中心位置，直到位置无变化
- 层级聚类


##### 自组织映射


#### 有监督学习（任务驱动，识别，分类，回归）

对于样本和标签进行分类。

1. 训练数据：
  - 样本
  - 标签
1. 模型（函数集合）
1. 定义函数好坏。
1. 找到最好的函数。


##### 参数方法

对于线性回归来说，通过定义误差=(模型计算值-样本标签值)的平方和来定义函数好坏。

使用梯度下降法找到最优解，适用于线性回归或多项式回归：
1. 用随机值初始化权重和偏差
1. 把输入传入网络，得到输出值
1. 计算预测值和真实值之间的误差
1. 对每一个产生误差的神经元，调整相应的（权重）值以减小误差
1. 重复迭代，直至得到网络权重的最佳值


##### 非参数方法


###### 决策树


##### 几何方法


###### 支持向量机

数据线性可分，离决策平面最近的点作为支撑向量。

使用逻辑回归法寻找最优解。

可用来进行文本和超文本分类，图像分类，新文章聚类，手写数字识别等。


##### 核方法

经过变换之后，线性可分。


##### 贝叶斯方法

朴素贝叶斯：假定每个符号出现的概率是条件独立的。

根据贝叶斯公式计算符号w出现时，是垃圾邮件的概率：
w在垃圾邮件中出现的概率x垃圾邮件的占比 / w在垃圾邮件中出现的概率x垃圾邮件的占比 + w在正常邮件中出现的概率x正常邮件的占比

1. 收集训练数据（4000正常邮件，4000垃圾邮件）
1. 计算每个符号w出现时，该邮件是垃圾邮件的概率
1. 如果w只出现在垃圾邮件中，设概率为0.99
1. 如果w只出现在正常邮件中，设概率为0.01
1. 对于新邮件，设正常邮件和垃圾邮件占比相同
1. 如果w在训练数据中没有出现过，设概率为0.4
1. 挑选离0.5最远的15个概率，计算当15个符号同时出现时：是垃圾邮件的概率积 / 是垃圾邮件的概率积 + 不是垃圾邮件的概率积
1. >0.9 认为是垃圾邮件


##### 概率图模型


##### 神经网络

使用多条线对数据进行划分。

- ANN(Artificial Neural Netword)：人工神经网络
  - 人工神经元（M-P Model）  
对输入x1, x2,...求加权weight和，加上偏置bias，通过激活函数threshold unit得到输出。  
激活函数：Unit step, Linear, Logistic, Hyperbolic tangent(sigmoid)...
  - 单层感知器（Single-Layer Perceptron）  
只能“一刀切”。
  - 多层感知器（Multi-Layer Perceptron）  
增加中间隐藏层。
- RNN(Recurrent Neural Network)：

---

- Back Propagation算法：误差平方和反向传递调整权重。  
局限性：步长太小fall in local minimum；步长太大不收敛；受初始点选择，权重，下降速率影响；无法使用数学证明；欠拟合过拟合。  
**应用：** 车牌识别（需要在单幅图片中对车牌进行裁切），手写数字识别。
- Hebb Rule：基于条件反射模型，由`误差 x 输入 x 系数`调整权值。
- Self-organizing Kohonen Rule：优先取影响较大的神经元。*无监督*
- Hopfield law：基于热力学能量定律，解决了“旅行推销员TSP”问题。
- LMS algorithm(Least Mean Square)：用最小方差来计算误差，采用梯度下降法学习。
- Competitive Learning竞争学习：胜者全取。*无监督*

---

- Supervised Learning: 有监督学习
- Unsupervised Learning: 无监督学习
- Reinforcement Learning: 强化学习
- Offline Learning: 离线学习（批处理）

---

- Training set: 训练样本
- Validation set: 验证微调
- Test set: 评估测试

---

- Classification: 分类
- Prediction: 预测
- Clustering: 聚类
- Pattern Recognition: 模式识别


batch梯度下降
随机梯度下降
Mini-batch梯度下降

大规模
深度

通过过滤器进行卷积，减少参数量

池化，减少冗余参数


###### 深度学习（多层神经网络）

适用于图像，语音的感知（识别），但欠缺推理，认知。


#### 强化学习（与环境互动）
